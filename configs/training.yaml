# Training configuration (shared by all training scripts)
epochs: 30
batch_size: 64
lr: 1e-3
weight_decay: 1e-4
patience: 7              # early stopping patience
checkpoint_dir: "checkpoints"
use_tensorboard: true
augmentation: true

# Domain-adapted training
regime: "real"            # "real" | "anonymized" | "mixed"
mix_ratio: 0.5            # fraction of anonymised data in mixed regime
synthetic_dir: "data/synthetic/blur"

# Anonymizer fine-tuning
finetune:
  lambda_expr: 1.0        # expression consistency loss weight
  lambda_id: 0.5          # identity suppression loss weight
  expr_temperature: 2.0   # KD temperature
  id_margin: 0.0          # cosine similarity margin
  finetune_epochs: 10
  finetune_lr: 1e-4
  finetune_batch_size: 8
  max_samples: 1000
